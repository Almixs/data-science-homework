{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmovRzwIvCsWTnRazVL7WX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":29,"metadata":{"id":"7Ro_oAISsxq_","executionInfo":{"status":"ok","timestamp":1713975807997,"user_tz":-180,"elapsed":241,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}}},"outputs":[],"source":["import numpy as np\n","\n","def hypothesis(w, X):\n","    \"\"\"\n","    Compute the hypothesis function for linear regression.\n","\n","    Parameters:\n","        w (numpy.array): Parameters vector of shape (n_features,).\n","        X (numpy.array): Input features matrix of shape (n_samples, n_features).\n","\n","    Returns:\n","        numpy.array: Predictions vector of shape (n_samples,).\n","    \"\"\"\n","    return np.dot(X, w)"]},{"cell_type":"code","source":["def compute_cost(w, X, y):\n","    \"\"\"\n","    Compute the cost function for linear regression.\n","\n","    Parameters:\n","        w (numpy.array): Parameters vector of shape (n_features,).\n","        X (numpy.array): Input features matrix of shape (n_samples, n_features).\n","        y (numpy.array): Target values vector of shape (n_samples,).\n","\n","    Returns:\n","        float: Value of the cost function.\n","    \"\"\"\n","    m = len(y)\n","    predictions = hypothesis(w, X)\n","    squared_errors = (predictions - y) ** 2\n","    cost = (1 / (2 * m)) * np.sum(squared_errors)\n","    return cost"],"metadata":{"id":"tO7G_0U7u9sM","executionInfo":{"status":"ok","timestamp":1713975824748,"user_tz":-180,"elapsed":334,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def gradient_descent_step(w, X, y, learning_rate):\n","    \"\"\"\n","    Perform one step of gradient descent for linear regression.\n","\n","    Parameters:\n","        w (numpy.array): Parameters vector of shape (n_features,).\n","        X (numpy.array): Input features matrix of shape (n_samples, n_features).\n","        y (numpy.array): Target values vector of shape (n_samples,).\n","        learning_rate (float): Learning rate or step size.\n","\n","    Returns:\n","        numpy.array: Updated parameters vector.\n","    \"\"\"\n","    m = len(y)\n","    predictions = hypothesis(w, X)\n","    errors = predictions - y\n","    gradient = (1 / m) * np.dot(X.T, errors)\n","    w -= learning_rate * gradient\n","    return w"],"metadata":{"id":"X6EN5L-DvIry","executionInfo":{"status":"ok","timestamp":1713975836341,"user_tz":-180,"elapsed":276,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","data = pd.read_csv(\"Housing.csv\")\n","\n","X = data[['area', 'bedrooms', 'bathrooms']].values\n","y = data['price'].values\n","\n","X = (X - X.mean(axis=0)) / X.std(axis=0)\n","\n","X = np.c_[np.ones(X.shape[0]), X]\n","\n","initial_w = np.zeros(X.shape[1])\n","\n","num_iterations = 1000\n","learning_rate = 0.01\n","\n","w = initial_w\n","for _ in range(num_iterations):\n","    w = gradient_descent_step(w, X, y, learning_rate)\n","\n","print(\"Найкращі параметри, отримані за допомогою градієнтного спуску:\")\n","print(w)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8cfglNay3ez","executionInfo":{"status":"ok","timestamp":1713975876513,"user_tz":-180,"elapsed":255,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}},"outputId":"654cfbc1-e1e5-4569-a4f6-a8c08af0d412"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Найкращі параметри, отримані за допомогою градієнтного спуску:\n","[4766523.46205873  821199.26709864  300296.28560637  695515.99623791]\n"]}]},{"cell_type":"code","source":["def normal_equation(X, y):\n","    \"\"\"\n","    Compute the parameters using the normal equation.\n","\n","    Parameters:\n","        X (numpy.array): Input features matrix of shape (n_samples, n_features).\n","        y (numpy.array): Target values vector of shape (n_samples,).\n","\n","    Returns:\n","        numpy.array: Parameters vector.\n","    \"\"\"\n","    return np.linalg.inv(X.T @ X) @ X.T @ y\n","\n","w_analytical = normal_equation(X, y)\n","\n","print(\"Найкращі параметри, отримані за допомогою аналітичного рішення:\")\n","print(w_analytical)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDzQgimT1JTQ","executionInfo":{"status":"ok","timestamp":1713975897916,"user_tz":-180,"elapsed":1940,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}},"outputId":"8dc935eb-4a08-4a92-def6-63755ad5eada"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Найкращі параметри, отримані за допомогою аналітичного рішення:\n","[4766729.24770642  821214.14349519  299983.57107963  695808.52272538]\n"]}]},{"cell_type":"code","source":["print(\"Порівняння результатів:\")\n","print(\"Градієнтний спуск:\", w)\n","print(\"Аналітичний розв'язок:\", w_analytical)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nA4J2ZlW1NOE","executionInfo":{"status":"ok","timestamp":1713975961221,"user_tz":-180,"elapsed":246,"user":{"displayName":"Dmytro Kutsupera","userId":"18183815949708069817"}},"outputId":"54d51817-3cb3-404e-db56-631d189d1fef"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Порівняння результатів:\n","Градієнтний спуск: [4766523.46205873  821199.26709864  300296.28560637  695515.99623791]\n","Аналітичний розв'язок: [4766729.24770642  821214.14349519  299983.57107963  695808.52272538]\n"]}]}]}