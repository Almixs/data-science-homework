{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import concurrent.futures"
      ],
      "metadata": {
        "id": "vFP645LYzSNR"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "a59af6_Py3fZ"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_resized = tf.image.resize(train_images[..., tf.newaxis], (32, 32))\n",
        "test_images_resized = tf.image.resize(test_images[..., tf.newaxis], (32, 32))"
      ],
      "metadata": {
        "id": "hPsWZ3bGy5Xj"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_rgb = tf.image.grayscale_to_rgb(train_images_resized)\n",
        "test_images_rgb = tf.image.grayscale_to_rgb(test_images_resized)"
      ],
      "metadata": {
        "id": "TnN4f9Hyy88_"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_rgb = tf.divide(train_images_rgb, 255.0)\n",
        "test_images_rgb = tf.divide(test_images_rgb, 255.0)\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "ukBiP9zSzBf-"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "yExP4nuDzHoI"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images_rgb, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images_rgb, test_labels)\n",
        "print(f'Test accuracy using VGG16 as feature extractor: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "YxgB0zmqzNGy",
        "outputId": "3d821a32-cccc-44e8-e5ca-983585c2205c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 729s 969ms/step - loss: 0.6007 - accuracy: 0.7931 - val_loss: 0.4753 - val_accuracy: 0.8258\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 731s 975ms/step - loss: 0.4332 - accuracy: 0.8416 - val_loss: 0.4295 - val_accuracy: 0.8463\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 725s 968ms/step - loss: 0.3970 - accuracy: 0.8564 - val_loss: 0.4200 - val_accuracy: 0.8466\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 713s 950ms/step - loss: 0.3739 - accuracy: 0.8625 - val_loss: 0.3954 - val_accuracy: 0.8538\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 724s 966ms/step - loss: 0.3583 - accuracy: 0.8683 - val_loss: 0.3943 - val_accuracy: 0.8575\n",
            "313/313 [==============================] - 129s 413ms/step - loss: 0.3995 - accuracy: 0.8581\n",
            "Test accuracy using VGG16 as feature extractor: 85.81%\n"
          ]
        }
      ]
    }
  ]
}